<html>
  
<head> 
<meta charset="UTF-8">
<meta name="description" content="Scale-Varying Triplet Ranking with Classification Loss for Facial Age Estimation">
<meta name="keywords" content="ACCV,paper,computer vision">
<meta name="author" content="Woobin Im">
<title>Scale-Varying Triplet Ranking with Classification Loss for Facial Age Estimation</title>
<link rel="stylesheet" href="template-style/style.css">
</head>

<body>
<div id="wrap">
<div id="conf-header">
<h3 class="conf-title">14th Asian Conference on Computer Vision (ACCV 2018)</h3>
    <a class="conf-logo" href ="http://accv2018.net/" style="background-color:black; padding:5px;">
        <img src="logo.png" alt="ACCV2018 Logo" height="35" width="142">
    </a>
</div>
<article>
<h2 id="paper-title">Scale-Varying Triplet Ranking with Classification Loss for Facial Age Estimation</h2>
<h2 id="paper-links"><a href="0639.pdf">[pdf]</a></h2>
<h3 id="authors">
<span class="author"><a href="/~wbim">Woobin Im</a></span>
<span class="author"><a href="https://sites.google.com/site/csehong/">Sungeun Hong</a></span>
<span class="author"><a href="/~sungeui">Sung-Eui Yoon</a></span>
<span class="author">Hyun S. Yang</span>
</h3>
<h3 id="institute">Korea Advanced Institute of Science and Technology (KAIST)</h3>

<section>
<figure style="max-width: 740px;">
<img src="overall.jpg">    
<figcaption style="">
    Figure 1. Overall network framework of our method. In the bottleneck layer, we
    apply the adaptive triplet ranking strategy (L_T : Eq. 6) by selecting triplets
    and computing the scale-varying triplet ranking loss. Our final objective jointly
    includes both the ranking (L_T : Eq. 6) and classification (L_C: Eq. 9) losses simultaneously.
</figcaption>
</figure>
<figure style="max-width: 740px;">
<img src="embedding.jpg">    
<figcaption style="">
    Figure 2. Embedding space visualization of a bottleneck feature of the network by
    T-SNE method. Input from test instances of the MORPH database.
</figcaption>
</figure>
<p>In the field of age estimation, CNNs have been widely exploited in a variety
of different approaches.
One of them is simple classification.
However, the classification loss, i.e. cross-entropy loss does not reflect
the ordinal characteristics of age labels; it focuses on whether the predicted
label is correct, but does not care about the degree of error between a prediction
and its target value.
To address the issue, we
take a feature learning approach by an end-to-end learning objective for CNN,
which is configured jointly from the proposed ranking constraint as well as the
classification loss.
Figure 1 shows the overall framework of our method.
</p>
<p>
By applying our method we can gather better features from face images (see figure 2),
and better age estimation results.
</p>
</section>

<section id="abstract">
<h2> Abstract</h2>
In recent years, considerable efforts based on convolutional
neural networks have been devoted to age estimation from face images.
Among them, classification-based approaches have shown promising results, 
but there has been little investigation of age differences and ordinal
age information. In this paper, we propose a ranking objective with two
novel schemes jointly performed with an age classification objective to
take ordinal age labels into account. We first introduce relative triplet
sampling in which a set of triplets is constructed considering the relative
differences in ages. This also addresses the problem of having limited
triplet candidates, that occurs in conventional triplet sampling. We then
propose the scale-varying ranking constraint, which decides the importance 
of a relative triplet and adjusts a scale of gradients accordingly. Our
adaptive ranking loss with relative sampling not only lowers the generalization 
error but ultimately has a meaningful performance improvement
over the state-of-the-art methods on two well-known benchmarks.
</section>

<footer id="kaist-cs-logo-footer">
<a href ="http://www.kaist.ac.kr/html/en/index.html"><img src="template-style/kaist_logo.png" height="40"></a>
<a href ="https://cs.kaist.ac.kr/"><img src="template-style/CS_logo.png" height="48"></a>
</footer>
</article>
</div> 
</body>
</html>
